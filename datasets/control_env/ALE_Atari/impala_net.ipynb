{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's implement the Impala small and large architectures from the paper\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "import gymnasium as gym\n",
    "from ray.rllib.models import ModelCatalog\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the RLLIB docs:\n",
    "Custom PyTorch Models\n",
    "Similarly, you can create and register custom PyTorch models by subclassing TorchModelV2 and implement the __init__() and forward() methods. forward() takes a dict of tensor inputs (mapping str to PyTorch tensor types), whose keys and values depend on the view requirements of the model. Usually, the dict contains only the current observation obs and an is_training boolean flag, as well as an optional list of RNN states. forward() should return the model output (of size self.num_outputs) and - if applicable - a new list of internal states (in case of RNNs or attention nets). You can also override extra methods of the model such as value_function to implement a custom value branch.\n",
    "\n",
    "Additional supervised/self-supervised losses can be added via the TorchModelV2.custom_loss method:\n",
    "\n",
    "See these examples of fully connected, convolutional, and recurrent torch models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a Conv model:\n",
    "https://github.com/ray-project/ray/blob/master/rllib/models/torch/visionnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ImpalaSmall(TorchModelV2,nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        super().__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self,obs):\n",
    "        obs = obs / 255.0\n",
    "        # First Conv2D layer with 16 8x8 filters with stride 4:\n",
    "        x = nn.Conv2d(3, 16, 8, stride = 4, padding = 0)(obs)\n",
    "        # ReLU activation\n",
    "        x = F.relu(x)\n",
    "        # Second Conv2D layer with 32 4x4 filters with stride 2:\n",
    "        x = nn.Conv2d(16, 32, 4, stride = 2, padding = 0)(x)\n",
    "        # ReLU activation\n",
    "        x = F.relu(x)\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Fully connected layer with 256 units\n",
    "        x = nn.Linear(32 * 9 * 9, 256)(x)\n",
    "        # ReLU activation\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "ModelCatalog.register_custom_model(\"impala_small\", ImpalaSmall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gato_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "784da5f53e3b84604e5b705801a93bcecccb5b17d6406e8b2a1917d1750ca222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
